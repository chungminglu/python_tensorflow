{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11554 images belonging to 9 classes.\n",
      "Found 3001 images belonging to 9 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_10 to have shape (None, 9) but got array with shape (1800, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ce8d851f8057>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     validation_steps=nb_validation_samples // batch_size)\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1115\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1557\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1558\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1559\u001b[1;33m             check_batch_axis=True)\n\u001b[0m\u001b[0;32m   1560\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1561\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1236\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1238\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1239\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1240\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    138\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_10 to have shape (None, 9) but got array with shape (1800, 1)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as ts\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 128, 128\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 11554\n",
    "nb_validation_samples = 3001\n",
    "epochs = 50\n",
    "batch_size = 1800\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size = (3,3),\n",
    "                 input_shape = input_shape,\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size = (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size = (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size = (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Conv2D(filters=128,\n",
    "                 kernel_size = (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(filters=128,\n",
    "                 kernel_size = (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(16384,\n",
    "                activation = 'relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "#建立輸出層 將輸出轉換成每一個預測影像類別的機率\n",
    "model.add(Dense(9,\n",
    "                activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_images_prediction(images,labels,prediction,idx,num=10):\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(12,14)\n",
    "    if num > 25: num=25\n",
    "    for i in range(0,num):\n",
    "        ax=plt.subplot(5,5,i+1)\n",
    "        ax.imshow(images[idx],cmap='binary')\n",
    "            \n",
    "        title=str(i)+','+label_dict[labels[i][0]]\n",
    "        if len(prediction)>0:\n",
    "            title+='=>'+label_dict[prediction[i]]\n",
    "        ax.set_title(title,fontsize = 10)\n",
    "        ax.set_xticks([]);ax.set_yticks([])\n",
    "        idx+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cPickle\n",
      "  Using cached cpickle-0.5.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"D:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\tokenize.py\", line 454, in open\n",
      "        buffer = _builtin_open(filename, 'rb')\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Java\\\\AppData\\\\Local\\\\Temp\\\\pip-build-sqsheroa\\\\cPickle\\\\setup.py'\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\Java\\AppData\\Local\\Temp\\pip-build-sqsheroa\\cPickle\\\n"
     ]
    }
   ],
   "source": [
    "!pip install cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11554 images belonging to 9 classes.\n",
      "Found 3001 images belonging to 9 classes.\n",
      "{'二條城': 1, '京都御所': 3, '渡月橋': 7, '京都塔': 2, '清水寺': 6, '金閣寺': 8, '千本鳥居': 4, '平等院鳳凰堂': 5, '三十三間堂': 0}\n",
      "{'二條城': 1, '京都御所': 3, '渡月橋': 7, '京都塔': 2, '清水寺': 6, '金閣寺': 8, '千本鳥居': 4, '平等院鳳凰堂': 5, '三十三間堂': 0}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16384)             134234112 \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 147465    \n",
      "=================================================================\n",
      "Total params: 134,668,585\n",
      "Trainable params: 134,668,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "115/115 [==============================] - 412s - loss: 1.4276 - acc: 0.4995 - val_loss: 1.2383 - val_acc: 0.5717\n",
      "Epoch 2/50\n",
      "115/115 [==============================] - 381s - loss: 1.0259 - acc: 0.6642 - val_loss: 0.9310 - val_acc: 0.6967\n",
      "Epoch 3/50\n",
      "115/115 [==============================] - 370s - loss: 0.8311 - acc: 0.7270 - val_loss: 0.9557 - val_acc: 0.6898\n",
      "Epoch 4/50\n",
      "115/115 [==============================] - 374s - loss: 0.7136 - acc: 0.7690 - val_loss: 0.6517 - val_acc: 0.7901\n",
      "Epoch 5/50\n",
      "115/115 [==============================] - 375s - loss: 0.6433 - acc: 0.7880 - val_loss: 0.6964 - val_acc: 0.7690\n",
      "Epoch 6/50\n",
      "115/115 [==============================] - 377s - loss: 0.5988 - acc: 0.8003 - val_loss: 0.6777 - val_acc: 0.7901\n",
      "Epoch 7/50\n",
      "115/115 [==============================] - 381s - loss: 0.5430 - acc: 0.8194 - val_loss: 0.5808 - val_acc: 0.8104\n",
      "Epoch 8/50\n",
      "115/115 [==============================] - 373s - loss: 0.5262 - acc: 0.8223 - val_loss: 0.5919 - val_acc: 0.8114\n",
      "Epoch 9/50\n",
      "115/115 [==============================] - 372s - loss: 0.4661 - acc: 0.8444 - val_loss: 0.5293 - val_acc: 0.8307\n",
      "Epoch 10/50\n",
      "115/115 [==============================] - 370s - loss: 0.4490 - acc: 0.8513 - val_loss: 0.4629 - val_acc: 0.8538\n",
      "Epoch 11/50\n",
      "115/115 [==============================] - 371s - loss: 0.4324 - acc: 0.8575 - val_loss: 0.5177 - val_acc: 0.8280\n",
      "Epoch 12/50\n",
      "115/115 [==============================] - 371s - loss: 0.3950 - acc: 0.8708 - val_loss: 0.4888 - val_acc: 0.8532\n",
      "Epoch 13/50\n",
      "115/115 [==============================] - 371s - loss: 0.3712 - acc: 0.8742 - val_loss: 0.5496 - val_acc: 0.8356\n",
      "Epoch 14/50\n",
      "115/115 [==============================] - 370s - loss: 0.3570 - acc: 0.8825 - val_loss: 0.5012 - val_acc: 0.8528\n",
      "Epoch 15/50\n",
      "115/115 [==============================] - 371s - loss: 0.3432 - acc: 0.8854 - val_loss: 0.5587 - val_acc: 0.8327\n",
      "Epoch 16/50\n",
      "115/115 [==============================] - 370s - loss: 0.3184 - acc: 0.8924 - val_loss: 0.4986 - val_acc: 0.8504\n",
      "Epoch 17/50\n",
      "115/115 [==============================] - 372s - loss: 0.2880 - acc: 0.9000 - val_loss: 0.5800 - val_acc: 0.8407\n",
      "Epoch 18/50\n",
      "115/115 [==============================] - 373s - loss: 0.2872 - acc: 0.9034 - val_loss: 0.5466 - val_acc: 0.8483\n",
      "Epoch 19/50\n",
      "115/115 [==============================] - 373s - loss: 0.2587 - acc: 0.9146 - val_loss: 0.5630 - val_acc: 0.8518\n",
      "Epoch 20/50\n",
      "115/115 [==============================] - 372s - loss: 0.2435 - acc: 0.9178 - val_loss: 0.5279 - val_acc: 0.8573\n",
      "Epoch 21/50\n",
      "115/115 [==============================] - 372s - loss: 0.2276 - acc: 0.9263 - val_loss: 0.4649 - val_acc: 0.8721\n",
      "Epoch 22/50\n",
      "115/115 [==============================] - 373s - loss: 0.2176 - acc: 0.9301 - val_loss: 0.5564 - val_acc: 0.8559\n",
      "Epoch 23/50\n",
      "115/115 [==============================] - 373s - loss: 0.2074 - acc: 0.9298 - val_loss: 0.5112 - val_acc: 0.8625\n",
      "Epoch 24/50\n",
      "115/115 [==============================] - 373s - loss: 0.2028 - acc: 0.9363 - val_loss: 0.5338 - val_acc: 0.8487\n",
      "Epoch 25/50\n",
      "115/115 [==============================] - 373s - loss: 0.1837 - acc: 0.9388 - val_loss: 0.6402 - val_acc: 0.8449\n",
      "Epoch 26/50\n",
      "115/115 [==============================] - 373s - loss: 0.1785 - acc: 0.9403 - val_loss: 0.5573 - val_acc: 0.8556\n",
      "Epoch 27/50\n",
      "115/115 [==============================] - 374s - loss: 0.1673 - acc: 0.9453 - val_loss: 0.5821 - val_acc: 0.8576\n",
      "Epoch 28/50\n",
      "115/115 [==============================] - 374s - loss: 0.1597 - acc: 0.9447 - val_loss: 0.6503 - val_acc: 0.8542\n",
      "Epoch 29/50\n",
      "115/115 [==============================] - 374s - loss: 0.1692 - acc: 0.9449 - val_loss: 0.6297 - val_acc: 0.8476\n",
      "Epoch 30/50\n",
      "115/115 [==============================] - 374s - loss: 0.1525 - acc: 0.9501 - val_loss: 0.6644 - val_acc: 0.8494\n",
      "Epoch 31/50\n",
      "115/115 [==============================] - 373s - loss: 0.1400 - acc: 0.9531 - val_loss: 0.6021 - val_acc: 0.8628\n",
      "Epoch 32/50\n",
      "115/115 [==============================] - 374s - loss: 0.1508 - acc: 0.9509 - val_loss: 0.6144 - val_acc: 0.8545\n",
      "Epoch 33/50\n",
      "115/115 [==============================] - 374s - loss: 0.1337 - acc: 0.9562 - val_loss: 0.6229 - val_acc: 0.8556\n",
      "Epoch 34/50\n",
      "115/115 [==============================] - 374s - loss: 0.1283 - acc: 0.9580 - val_loss: 0.6999 - val_acc: 0.8466\n",
      "Epoch 35/50\n",
      "115/115 [==============================] - 374s - loss: 0.1445 - acc: 0.9534 - val_loss: 0.5742 - val_acc: 0.8669\n",
      "Epoch 36/50\n",
      "115/115 [==============================] - 374s - loss: 0.0998 - acc: 0.9664 - val_loss: 0.7154 - val_acc: 0.8618\n",
      "Epoch 37/50\n",
      "115/115 [==============================] - 374s - loss: 0.1164 - acc: 0.9621 - val_loss: 0.6391 - val_acc: 0.8507\n",
      "Epoch 38/50\n",
      "115/115 [==============================] - 375s - loss: 0.1189 - acc: 0.9615 - val_loss: 0.7261 - val_acc: 0.8573\n",
      "Epoch 39/50\n",
      "115/115 [==============================] - 374s - loss: 0.1022 - acc: 0.9667 - val_loss: 0.7066 - val_acc: 0.8611\n",
      "Epoch 40/50\n",
      "115/115 [==============================] - 375s - loss: 0.1111 - acc: 0.9657 - val_loss: 0.7279 - val_acc: 0.8549\n",
      "Epoch 41/50\n",
      "115/115 [==============================] - 375s - loss: 0.1031 - acc: 0.9665 - val_loss: 0.7435 - val_acc: 0.8452\n",
      "Epoch 42/50\n",
      "115/115 [==============================] - 374s - loss: 0.1028 - acc: 0.9682 - val_loss: 0.7755 - val_acc: 0.8421\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 374s - loss: 0.1110 - acc: 0.9659 - val_loss: 0.5712 - val_acc: 0.8738\n",
      "Epoch 44/50\n",
      "115/115 [==============================] - 374s - loss: 0.1069 - acc: 0.9671 - val_loss: 0.6989 - val_acc: 0.8607\n",
      "Epoch 45/50\n",
      "115/115 [==============================] - 374s - loss: 0.0815 - acc: 0.9750 - val_loss: 0.7414 - val_acc: 0.8480\n",
      "Epoch 46/50\n",
      "115/115 [==============================] - 375s - loss: 0.0964 - acc: 0.9702 - val_loss: 0.7578 - val_acc: 0.8540\n",
      "Epoch 47/50\n",
      "115/115 [==============================] - 374s - loss: 0.0948 - acc: 0.9707 - val_loss: 0.8318 - val_acc: 0.8414\n",
      "Epoch 48/50\n",
      "115/115 [==============================] - 374s - loss: 0.0947 - acc: 0.9689 - val_loss: 0.6793 - val_acc: 0.8628\n",
      "Epoch 49/50\n",
      "115/115 [==============================] - 373s - loss: 0.0974 - acc: 0.9686 - val_loss: 0.6202 - val_acc: 0.8649\n",
      "Epoch 50/50\n",
      "115/115 [==============================] - 374s - loss: 0.0803 - acc: 0.9761 - val_loss: 0.8198 - val_acc: 0.8452\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'show_train_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d501c422fc69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    156\u001b[0m                         validation_steps= nb_validation_samples // batch_size)\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m \u001b[0mshow_train_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;31m# except:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;31m#     pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'show_train_history' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################\n",
    "#                             #\n",
    "#          DEMO_05            #\n",
    "#                             #\n",
    "###############################\n",
    "\n",
    "# 解bug\n",
    "# Python：IOError: image file is truncated 的解决办法\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as ts\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True # 解bug\n",
    "\n",
    "#############################################################################################\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 11554\n",
    "nb_validation_samples = 3001\n",
    "epochs = 50 # 訓練\n",
    "batch_size = 100\n",
    "\n",
    "    ##################################################################\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(64, 64),\n",
    "            batch_size=100,\n",
    "            class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "            validation_data_dir,\n",
    "            target_size=(64, 64),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "\n",
    "    ##################################################################\n",
    "\n",
    "print(train_generator.class_indices)  # 印出標籤\n",
    "print(validation_generator.class_indices)  # 印出標籤\n",
    "\n",
    "    ##################################################################\n",
    "\n",
    "model = Sequential() # 建立model\n",
    "\n",
    "    ##################################################################\n",
    "\n",
    "    # 加入卷積層1\n",
    "model.add(Conv2D(filters=32, kernel_size = (3,3),   # 32個3*3濾鏡\n",
    "                     input_shape = (64,64,3),   # 圖片大小&三原色\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same' # 經過此層影像大小不變\n",
    "                     ) \n",
    "             )\n",
    "\n",
    "\n",
    "    # 控制overfit\n",
    "model.add(Dropout(rate=0.25))    \n",
    "\n",
    "\n",
    "    # 加入池化層1\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size = (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    ##################################################################\n",
    "\n",
    "    # 加入卷積層2\n",
    "model.add(Conv2D(filters=64, kernel_size = (3,3),   # 64個3*3濾鏡\n",
    "                     activation = 'relu',\n",
    "                     padding = 'same' # 經過此層影像大小不變\n",
    "                     ) \n",
    "             )\n",
    "    \n",
    "\n",
    "    # 控制overfit\n",
    "model.add(Dropout(rate=0.25))          \n",
    "model.add(Conv2D(filters=64,\n",
    "                 kernel_size = (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "\n",
    "    # 加入池化層2\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "    #################################################################\n",
    "model.add(Conv2D(filters=128,\n",
    "                 kernel_size = (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(filters=128,\n",
    "                 kernel_size = (3,3),\n",
    "                 activation = 'relu',\n",
    "                 padding = 'same'))\n",
    "    ##################################################################\n",
    "\n",
    "    # 加入平坦層\n",
    "model.add(Flatten()) #28*28*64\n",
    "\n",
    "\n",
    "    # 控制overfit\n",
    "model.add(Dropout(rate=0.25))    \n",
    "\n",
    "\n",
    "    ##################################################################\n",
    "\n",
    "    # 加入隱藏層\n",
    "model.add(Dense(16384, activation = 'relu'))\n",
    "\n",
    "\n",
    "    # 控制overfit\n",
    "model.add(Dropout(rate=0.25))    \n",
    "\n",
    "    ##################################################################\n",
    "\n",
    "    # 建立輸出層\n",
    "model.add(Dense(9, activation = 'softmax'))\n",
    "\n",
    "    ##################################################################\n",
    "\n",
    "    # 查看模型摘要\n",
    "print(model.summary())\n",
    "\n",
    "    ##################################################################\n",
    "\n",
    "    ###############################\n",
    "    #                             #\n",
    "    #          準備訓練            #\n",
    "    #                             #\n",
    "    ###############################\n",
    "model.compile(loss = 'categorical_crossentropy',  # 損失函數\n",
    "                  optimizer = 'adam',                 # 最優化方法\n",
    "                  metrics = ['accuracy'])             # 以準確率評估\n",
    "\n",
    "##################################################################\n",
    "\n",
    "train_history = model.fit_generator(\n",
    "                        train_generator,\n",
    "                        steps_per_epoch=nb_train_samples // batch_size,\n",
    "                        epochs=50,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps= nb_validation_samples // batch_size)\n",
    "\n",
    "show_train_history(train_history,'acc','val_acc')\n",
    "# except:\n",
    "#     pass\n",
    "#########################################################################################\n",
    "\n",
    "# 過程問題: 建立資料集，輸入資料集，演算法選擇，層數問題，圖片大小問題，三原色... etc(待補)    \n",
    "# 問題: 太慢                                                                            \n",
    "# 問題: 演算法未優化                                                                      \n",
    "# 問題: 只用了四種                                                                      \n",
    "# 問題: size是否有問題                                                                  \n",
    "# 問題: 迭代次數太少                                                                    \n",
    "                                                                                    \n",
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'D:\\\\tensorflow\\\\data\\\\*'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ea0b67f49431>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# import cPickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m##圖片目錄\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:\\\\tensorflow\\\\data\\\\*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# # numpy supports conversion from image to ndarray and normalization by dividing 255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2411\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'D:\\\\tensorflow\\\\data\\\\*'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
